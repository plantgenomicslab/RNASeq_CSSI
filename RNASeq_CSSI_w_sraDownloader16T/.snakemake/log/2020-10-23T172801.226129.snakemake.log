Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	all
	113	sraDownload
	114

[Fri Oct 23 17:29:23 2020]
Job 111: ~-~ Downloading sra files... -~-

Terminating processes on user request, this might take some time.
[Fri Oct 23 17:40:28 2020]
Error in rule sraDownload:
    jobid: 111
    output: output/SRR949965/SRA/SRR949965
    shell:
        python src/sra_downloader.py -i data/samples.tsv -o output/SRR949965/SRA/
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Removing output files of failed job sraDownload since they might be corrupted:
output/SRR949965/SRA/SRR949965
Complete log: /data/gpfs/assoc/pgl/Froi/data/RNASeq_CSSI/RNASeq_CSSI_w_sraDownloader16T/.snakemake/log/2020-10-23T172801.226129.snakemake.log
